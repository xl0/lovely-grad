{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§¾ View as a summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp repr_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "import os\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import test_eq, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "os.environ[\"DEBUG\"]=\"0\"\n",
    "os.environ[\"CPU\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "\n",
    "import warnings\n",
    "from typing import Union, Optional as O\n",
    "\n",
    "import numpy as np\n",
    "# import jax, jax.numpy as jnp\n",
    "\n",
    "from lovely_numpy import np_to_str_common, pretty_str, sparse_join, ansi_color, in_debugger, bytes_to_human\n",
    "from lovely_numpy import config as lnp_config\n",
    "\n",
    "from lovely_grad.utils.config import get_config, config, set_config\n",
    "from lovely_grad.utils.misc import is_cpu\n",
    "\n",
    "import tinygrad.helpers, tinygrad.tensor\n",
    "from tinygrad.tensor import Tensor, DType, dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "np.random.seed(1337)\n",
    "\n",
    "randoms = np.random.randn(100,).astype(np.float32)\n",
    "\n",
    "spicy = randoms[:12].copy()\n",
    "spicy[0] *= 10000.0\n",
    "spicy[1] /= 10000.0\n",
    "spicy[3] = np.Inf\n",
    "spicy[4] = np.NINF\n",
    "spicy[5] = np.NaN\n",
    "spicy = spicy.reshape((2,6))\n",
    "\n",
    "\n",
    "# Works with gpu too, but I keep cpu for CI testing to match the outputs.\n",
    "randoms = Tensor(randoms, device=\"cpu\")\n",
    "spicy = Tensor(spicy, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exporti\n",
    "dtnames =   {   \"half\": \"f16\",\n",
    "                \"float\": \"f32\",\n",
    "                \"char\": \"i8\",\n",
    "                \"uchar\": \"u8\",\n",
    "                \"int\":   \"i32\",\n",
    "                \"int64\": \"i64\",\n",
    "            }\n",
    "\n",
    "\n",
    "def short_dtype(x: DType) -> str:\n",
    "    return dtnames.get(x.dtype.name, str(x.dtype)) if x.dtype != Tensor.default_type else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# test_eq(short_dtype(jnp.array(1., dtype=jnp.bfloat16)), \"bf16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "def plain_repr(x: Tensor):\n",
    "    \"Pick the right function to get a plain repr\"\n",
    "    # assert isinstance(x, np.ndarray), f\"expected np.ndarray but got {type(x)}\" # Could be a sub-class.\n",
    "    return x._plain_repr() if hasattr(x, \"_plain_repr\") else repr(x)\n",
    "\n",
    "# def plain_str(x: torch.Tensor):\n",
    "#     \"Pick the right function to get a plain str.\"\n",
    "#     # assert isinstance(x, np.ndarray), f\"expected np.ndarray but got {type(x)}\"\n",
    "#     return x._plain_str() if hasattr(type(x), \"_plain_str\") else str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "def is_nasty(x: Tensor):\n",
    "    \"\"\"Return true of any `x` values are inf or nan\"\"\"\n",
    "    if x.shape == (): return False # min/max don't like zero-lenght arrays\n",
    "    \n",
    "    x_min = x.min().numpy().squeeze()\n",
    "    x_max = x.max().numpy().squeeze()\n",
    "\n",
    "    return np.isnan(x_min) or np.isinf(x_min) or np.isinf(x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test_eq(is_nasty(Tensor([1, 2, float(\"nan\")])), True) ### Fix tinygrad/#862 first\n",
    "test_eq(is_nasty(Tensor([1, 2, float(\"inf\")])), True)\n",
    "test_eq(is_nasty(Tensor([1, 2, 3])), False)\n",
    "# test_eq(is_nasty(Tensor([])), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def tensor_to_str_common(x: Tensor,  # Input\n",
    "                        color=True,  # ANSI color highlighting\n",
    "                        ddof=0):     # For \"std\" unbiasing\n",
    "\n",
    "    if x.numel() == 0: return ansi_color(\"empty\", \"grey\", color)\n",
    "    if x.eq(0).min().eq(1).numpy(): return ansi_color(\"all_zeros\", \"grey\", color)\n",
    "\n",
    "    if x.ndim > 0:\n",
    "        x_min = x.min().numpy().squeeze()\n",
    "        x_max = x.max().numpy().squeeze()\n",
    "        minmax = f\"xâˆˆ[{pretty_str(x_min)}, {pretty_str(x_max)}]\" if x.numel() > 2 else None\n",
    "\n",
    "        # XXX Add bias correction?\n",
    "        x_mean = x.mean().numpy().squeeze()\n",
    "        x_std = x.std().numpy().squeeze()\n",
    "        meanstd = f\"Î¼={pretty_str(x_mean)} Ïƒ={pretty_str(x_std)}\" if x.numel() >= 2 else None\n",
    "\n",
    "        return sparse_join([minmax, meanstd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exporti\n",
    "\n",
    "def to_str(x: Tensor,  # Input\n",
    "            verbose:        bool    =False,\n",
    "            auto_realize:    O[bool] =None,\n",
    "            depth:          int     =0,\n",
    "            lvl:            int     =0,\n",
    "            color:          O[bool] =None\n",
    "        ) -> str:\n",
    "\n",
    "    # if plain:\n",
    "    #     return plain_repr(x)\n",
    "\n",
    "    conf = get_config()\n",
    "    if color is None: color=conf.color\n",
    "    if auto_realize is None: auto_realize=conf.auto_realize\n",
    "\n",
    "    if in_debugger(): color = False\n",
    "\n",
    "\n",
    "    tname = type(x).__name__.split(\".\")[-1]             # Tensor\n",
    "    shape = str(list(x.shape)) if (x.ndim) else None   # [1,2,3]\n",
    "    type_str = sparse_join([tname, shape], sep=\"\")      # Tensor[1,2,3]\n",
    "\n",
    "    dtype = short_dtype(x)                              # f16\n",
    "    dev = x.device                                      # CPU\n",
    "\n",
    "    grad = \"grad\" if x.requires_grad else None          # grad\n",
    "    if x.grad is not None: grad = grad + ansi_color(\"+\", \"green\", color)\n",
    "\n",
    "\n",
    "    numel = None\n",
    "    if x.shape and max(x.shape) != x.numel():\n",
    "        numel = f\"n={x.ndim}\"\n",
    "        # if get_config().show_mem_above <= x.nbytes:\n",
    "        #     numel = sparse_join([numel, f\"({bytes_to_human(x.nbytes)})\"])\n",
    "    # elif get_config().show_mem_above <= x.nbytes:\n",
    "        # numel = bytes_to_human(x.nbytes)\n",
    "\n",
    "\n",
    "    just_realized = None\n",
    "    if auto_realize and not x.lazydata.realized:\n",
    "        just_realized = ansi_color(\"Realized \"+ str(x.lazydata.op.op).split(\".\")[-1], \"grey\", color)\n",
    "        x.realize()\n",
    "\n",
    "    res  = \"\"\n",
    "    if x.lazydata.realized:\n",
    "        # `lovely-numpy` is used to calculate stats when doing so on GPU would require\n",
    "        # memory allocation (no-float tensors, tensors with bad numbers),\n",
    "        #\n",
    "        # Temporarily set the numpy config to match our config for consistency.\n",
    "        with lnp_config(precision=conf.precision,\n",
    "                        threshold_min=conf.threshold_min,\n",
    "                        threshold_max=conf.threshold_max,\n",
    "                        sci_mode=conf.sci_mode):\n",
    "\n",
    "            if is_nasty(x) or not x.is_floating_point():\n",
    "                common = np_to_str_common(x.numpy(), color=color)\n",
    "            else:\n",
    "                common = tensor_to_str_common(x, color=color)\n",
    "\n",
    "            vals = pretty_str(x.numpy()) if 0 < x.numel() <= 10 else None\n",
    "            res = sparse_join([type_str, dtype, numel, common, grad, dev,  vals, just_realized])\n",
    "    else:\n",
    "        op = \"Lazy \" + str(x.lazydata.op.op).split(\".\")[-1]\n",
    "        res = sparse_join([type_str, dtype, numel, grad, dev, op])\n",
    "    # else:\n",
    "    #     res = plain_repr(x)\n",
    "\n",
    "    if verbose:\n",
    "        res += \"\\n\" + plain_repr(x)\n",
    "\n",
    "    if depth and x.ndim > 1:\n",
    "        with config(show_mem_above=np.inf):\n",
    "            deep_width = min((x.shape[0]), conf.deeper_width) # Print at most this many lines\n",
    "            deep_lines = [ \" \"*conf.indent*(lvl+1) + to_str(x[i,:].realize(), depth=depth-1, lvl=lvl+1)\n",
    "                                for i in range(deep_width)] \n",
    "\n",
    "            # If we were limited by width, print ...\n",
    "            if deep_width < x.shape[0]: deep_lines.append(\" \"*conf.indent*(lvl+1) + \"...\")\n",
    "\n",
    "            res += \"\\n\" + \"\\n\".join(deep_lines)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exporti\n",
    "def history_warning():\n",
    "    \"Issue a warning (once) ifw e are running in IPYthon with output cache enabled\"\n",
    "\n",
    "    if \"get_ipython\" in globals() and get_ipython().cache_size > 0:\n",
    "        warnings.warn(\"IPYthon has its output cache enabled. See https://xl0.github.io/lovely-tensors/history.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87341/3648473780.py:6: UserWarning: IPYthon has its output cache enabled. See https://xl0.github.io/lovely-tensors/history.html\n",
      "  warnings.warn(\"IPYthon has its output cache enabled. See https://xl0.github.io/lovely-tensors/history.html\")\n"
     ]
    }
   ],
   "source": [
    "# |hide\n",
    "get_ipython().cache_size=1000\n",
    "history_warning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "get_ipython().cache_size=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "class StrProxy():\n",
    "    def __init__(self, x: Tensor, plain=False, verbose=False, depth=0, lvl=0, color=None):\n",
    "        self.x = x\n",
    "        self.plain = plain\n",
    "        self.verbose = verbose\n",
    "        self.depth=depth\n",
    "        self.lvl=lvl\n",
    "        self.color=color\n",
    "        history_warning()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if self.plain: return plain_repr(self.x)\n",
    "        return to_str(self.x, verbose=self.verbose,\n",
    "                      depth=self.depth, lvl=self.lvl, color=self.color)\n",
    "\n",
    "    # This is used for .deeper attribute and .deeper(depth=...).\n",
    "    # The second onthe results in a __call__.\n",
    "    def __call__(self, depth=1):\n",
    "        return StrProxy(self.x, depth=depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def lovely(x: Tensor, # Tensor of interest\n",
    "            verbose=False,  # Whether to show the full tensor\n",
    "            depth=0,        # Show stats in depth\n",
    "            color=None):    # Force color (True/False) or auto.\n",
    "    return StrProxy(x, verbose=verbose, depth=depth, color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Control laziness of repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor[2, 6] n=2 CPU Lazy FROMCPU,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_config(auto_realize=False)\n",
    "lovely(spicy),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor[2, 6] n=2 CPU Lazy FROMCPU"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovely(spicy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor[2, 6] n=2 xâˆˆ[-7.032e+03, 1.549] Î¼=-781.232 Ïƒ=2.210e+03 \u001b[31m+Inf!\u001b[0m \u001b[31m-Inf!\u001b[0m \u001b[31mNaN!\u001b[0m CPU \u001b[38;2;127;127;127mRealized FROMCPU\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_config(auto_realize=True)\n",
    "lovely(spicy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor[2, 6] n=2 xâˆˆ[-7.032e+03, 1.549] Î¼=-781.232 Ïƒ=2.210e+03 \u001b[31m+Inf!\u001b[0m \u001b[31m-Inf!\u001b[0m \u001b[31mNaN!\u001b[0m CPU"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovely(spicy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show the stats and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor[1] CPU [-0.703] \u001b[38;2;127;127;127mRealized SHRINK\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovely(randoms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor[2] Î¼=-0.597 Ïƒ=0.106 CPU [-0.703, -0.490] \u001b[38;2;127;127;127mRealized SHRINK\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovely(randoms[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor[2, 3] n=2 xâˆˆ[-2.011, 0.207] Î¼=-0.846 Ïƒ=0.787 CPU [[-0.703, -0.490, -0.322], [-1.755, 0.207, -2.011]] \u001b[38;2;127;127;127mRealized RESHAPE\u001b[0m,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lovely(randoms[:6].reshape((2, 3))), # More than 2 elements -> show statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor[11] xâˆˆ[-2.011, 1.549] Î¼=-0.336 Ïƒ=1.108 CPU \u001b[38;2;127;127;127mRealized SHRINK\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovely(randoms[:11])                # More than 10 -> suppress data output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# test_eq(str(lovely(randoms[0])),                'Tensor[1] CPU \\x1b[38;2;127;127;127mRealized SHRINK\\x1b[0m [-0.703]')\n",
    "# test_eq(str(lovely(randoms[:2])),               'Tensor[2] Î¼=-0.597 Ïƒ=0.106 CPU \\x1b[38;2;127;127;127mRealized SHRINK\\x1b[0m [-0.703, -0.490]')\n",
    "# test_eq(str(lovely(randoms[:6].reshape(2, 3))), 'Tensor[2, 3] n=2 xâˆˆ[-2.011, 0.207] Î¼=-0.846 Ïƒ=0.787 CPU \\x1b[38;2;127;127;127mRealized RESHAPE\\x1b[0m [[-0.703, -0.490, -0.322], [-1.755, 0.207, -2.011]]')\n",
    "# test_eq(str(lovely(randoms[:11])),              'Tensor[11] xâˆˆ[-2.011, 1.549] Î¼=-0.336 Ïƒ=1.108 CPU')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor[3] xâˆˆ[1.000, 3.000] Î¼=2.000 Ïƒ=0.816 grad CPU [1.000, 2.000, 3.000] \u001b[38;2;127;127;127mRealized FROMCPU\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g=Tensor([1,2,3], requires_grad=True)\n",
    "lovely(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor[3] xâˆˆ[1.000, 3.000] Î¼=2.000 Ïƒ=0.816 grad\u001b[32m+\u001b[0m CPU [1.000, 2.000, 3.000]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(g*g).sum().backward()\n",
    "lovely(g)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "\n",
    "Note the green '<span style=\"color: green;\">+</span>'  when the gradient is available.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor[3] xâˆˆ[2.000, 6.000] Î¼=4.000 Ïƒ=1.633 CPU [2.000, 4.000, 6.000] \u001b[38;2;127;127;127mRealized ADD\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovely(g.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Do we have __any__ floating point nasties?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor[2, 6] n=2 xâˆˆ[-7.032e+03, 1.549] Î¼=-781.232 Ïƒ=2.210e+03 \u001b[31m+Inf!\u001b[0m \u001b[31m-Inf!\u001b[0m \u001b[31mNaN!\u001b[0m CPU"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistics and range are calculated on good values only, if there are at lest 3 of them.\n",
    "lovely(spicy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor[2, 6] n=2 xâˆˆ[-7.032e+03, 1.549] Î¼=-781.232 Ïƒ=2.210e+03 +Inf! -Inf! NaN! CPU"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovely(spicy, color=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor[11] \u001b[31mNaN!\u001b[0m CPU \u001b[38;2;127;127;127mRealized FROMCPU\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovely(Tensor([float(\"nan\")]*11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Is the tensor __all__ zeros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor[12] \u001b[38;2;127;127;127mall_zeros\u001b[0m CPU \u001b[38;2;127;127;127mRealized CONTIGUOUS\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovely(Tensor.zeros(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# test_array_repr(str(lovely(jnp.zeros(12))),\n",
    "#         'Array[12] \\x1b[38;2;127;127;127mall_zeros\\x1b[0m gpu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX empty tensors - fix when they work\n",
    "# lovely(jnp.array([], dtype=jnp.float16).reshape((0,0,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# test_array_repr(str(lovely(jnp.array([], dtype=jnp.float16).reshape((0,0,0)))),\n",
    "#         'Array[0, 0, 0] f16 \\x1b[38;2;127;127;127mempty\\x1b[0m gpu:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shows the dtype if it's not the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor[3] i8 xâˆˆ[1, 3] Î¼=2.000 Ïƒ=0.816 CPU [1, 2, 3]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovely(Tensor([1,2,3], dtype=dtypes.int8).realize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# test_array_repr(str(lovely(jnp.array([1,2,3], dtype=jnp.int32))),\n",
    "#         'Array[3] i32 xâˆˆ[1, 3] Î¼=2.000 Ïƒ=0.816 gpu:0 [1, 2, 3]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor[2, 6] n=2 xâˆˆ[-7.032e+03, 1.549] Î¼=-781.232 Ïƒ=2.210e+03 \u001b[31m+Inf!\u001b[0m \u001b[31m-Inf!\u001b[0m \u001b[31mNaN!\u001b[0m CPU\n",
       "<Tensor buffer<12, dtypes.float> on CPU with grad None>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovely(spicy, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We need to go deeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor[3, 196, 196] n=3 xâˆˆ[-2.118, 2.640] Î¼=-0.388 Ïƒ=1.073 \u001b[31mNaN!\u001b[0m CPU \u001b[38;2;127;127;127mRealized FROMCPU\u001b[0m\n",
       "  Tensor[196, 196] n=2 xâˆˆ[-2.118, 2.249] Î¼=-0.324 Ïƒ=1.036 CPU\n",
       "    Tensor[196] xâˆˆ[-1.912, 2.249] Î¼=-0.673 Ïƒ=0.521 CPU\n",
       "    Tensor[196] xâˆˆ[-1.861, 2.163] Î¼=-0.738 Ïƒ=0.417 CPU\n",
       "    Tensor[196] xâˆˆ[-1.758, 2.198] Î¼=-0.806 Ïƒ=0.396 CPU\n",
       "    Tensor[196] xâˆˆ[-1.656, 2.249] Î¼=-0.849 Ïƒ=0.368 CPU\n",
       "    Tensor[196] xâˆˆ[-1.673, 2.198] Î¼=-0.857 Ïƒ=0.356 CPU\n",
       "    Tensor[196] xâˆˆ[-1.656, 2.146] Î¼=-0.848 Ïƒ=0.371 CPU\n",
       "    Tensor[196] xâˆˆ[-1.433, 2.215] Î¼=-0.784 Ïƒ=0.396 CPU\n",
       "    Tensor[196] xâˆˆ[-1.279, 2.249] Î¼=-0.695 Ïƒ=0.485 CPU\n",
       "    Tensor[196] xâˆˆ[-1.364, 2.249] Î¼=-0.637 Ïƒ=0.538 CPU\n",
       "    ...\n",
       "  Tensor[196, 196] n=2 xâˆˆ[-1.966, 2.429] Î¼=-0.274 Ïƒ=0.973 \u001b[31mNaN!\u001b[0m CPU\n",
       "    Tensor[196] xâˆˆ[-1.861, 2.411] Î¼=-0.529 Ïƒ=0.555 CPU\n",
       "    Tensor[196] xâˆˆ[-1.826, 2.359] Î¼=-0.562 Ïƒ=0.472 CPU\n",
       "    Tensor[196] xâˆˆ[-1.756, 2.376] Î¼=-0.622 Ïƒ=0.458 \u001b[31mNaN!\u001b[0m CPU\n",
       "    Tensor[196] xâˆˆ[-1.633, 2.429] Î¼=-0.664 Ïƒ=0.429 CPU\n",
       "    Tensor[196] xâˆˆ[-1.651, 2.376] Î¼=-0.669 Ïƒ=0.398 CPU\n",
       "    Tensor[196] xâˆˆ[-1.633, 2.376] Î¼=-0.701 Ïƒ=0.390 CPU\n",
       "    Tensor[196] xâˆˆ[-1.563, 2.429] Î¼=-0.670 Ïƒ=0.379 CPU\n",
       "    Tensor[196] xâˆˆ[-1.475, 2.429] Î¼=-0.616 Ïƒ=0.385 CPU\n",
       "    Tensor[196] xâˆˆ[-1.511, 2.429] Î¼=-0.593 Ïƒ=0.398 CPU\n",
       "    ...\n",
       "  Tensor[196, 196] n=2 xâˆˆ[-1.804, 2.640] Î¼=-0.567 Ïƒ=1.178 CPU\n",
       "    Tensor[196] xâˆˆ[-1.717, 2.396] Î¼=-0.982 Ïƒ=0.349 CPU\n",
       "    Tensor[196] xâˆˆ[-1.752, 2.326] Î¼=-1.034 Ïƒ=0.313 CPU\n",
       "    Tensor[196] xâˆˆ[-1.648, 2.379] Î¼=-1.086 Ïƒ=0.313 CPU\n",
       "    Tensor[196] xâˆˆ[-1.630, 2.466] Î¼=-1.121 Ïƒ=0.304 CPU\n",
       "    Tensor[196] xâˆˆ[-1.717, 2.448] Î¼=-1.120 Ïƒ=0.301 CPU\n",
       "    Tensor[196] xâˆˆ[-1.717, 2.431] Î¼=-1.166 Ïƒ=0.313 CPU\n",
       "    Tensor[196] xâˆˆ[-1.560, 2.448] Î¼=-1.124 Ïƒ=0.325 CPU\n",
       "    Tensor[196] xâˆˆ[-1.421, 2.431] Î¼=-1.064 Ïƒ=0.382 CPU\n",
       "    Tensor[196] xâˆˆ[-1.526, 2.396] Î¼=-1.047 Ïƒ=0.416 CPU\n",
       "    ..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = np.load(\"mysteryman.npy\")\n",
    "image[1,2,3] = float('nan')\n",
    "\n",
    "image = Tensor(image)\n",
    "\n",
    "lovely(image, depth=2) # Limited by set_config(deeper_lines=N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
